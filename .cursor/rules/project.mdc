---
description: Project document
alwaysApply: false
---
# 5Tran AI Pipeline Automation - Cursor Rules (Dev Prototype)

## Project Overview
You are building a development prototype of an AI-powered data pipeline automation system that creates end-to-end data pipelines using Fivetran connectors, dbt transformations, and BigQuery as the destination. The system uses Google's ADK (AI Development Kit) with Gemini API for AI capabilities, enabling users to describe data requirements in natural language and automatically generate the necessary infrastructure.

## Core Technologies
- **AI Framework**: Google Gemini API
- **Language**: Python 3.11+
- **UI**: Gradio for rapid prototyping
- **Data Pipeline**: Fivetran Connector SDK (real API, no mocks), dbt-core for transformations
- **Data Warehouse**: Google BigQuery
- **API Specification**: OpenAPI/Swagger for source definitions
- **Deployment**: One-click deployment from UI with auto-generated SDK connectors

## Project Structure
```
fivetran-ai-automation/
├── src/
│   ├── agent/           # Google ADK/Gemini orchestration
│   ├── connectors/      # Fivetran SDK integration
│   ├── transformations/ # dbt model generation
│   ├── warehouse/       # BigQuery schema management
│   └── ui/             # Gradio interface
├── configs/            # YAML configurations and prompts
├── dbt_project/        # Generated dbt models
└── examples/           # Example OpenAPI specs and use cases
```

## Development Focus
This is a development prototype - prioritize functionality over production concerns. Focus on proving the concept works end-to-end before optimizing.

## Google ADK & Gemini Integration

### Quick Setup
- Use Google ADK for all AI-related functionalities
- Configure Gemini API with a simple API key authentication
- Use gemini-1.5-flash for faster responses during development
- Switch to gemini-1.5-pro for more complex reasoning when needed

### Gemini Prompt Guidelines
- Use clear, direct prompts without over-engineering
- Request JSON responses for structured data extraction
- Include examples in prompts for better accuracy
- Keep temperature low (0.1-0.3) for consistent outputs
- Store prompts as strings in Python files for easy editing

### Function Calling with Gemini
- Define tools for Fivetran operations, dbt generation, and BigQuery management
- Use ADK's function calling to trigger pipeline operations
- Keep function descriptions simple and clear
- Return structured responses that can be easily parsed

## Fivetran Integration

### Connector Setup
- Parse OpenAPI specifications to extract endpoints and schemas
- Generate Fivetran API connector configurations
- Focus on REST API sources for the MVP
- Use basic authentication methods (API key, bearer token)
- Handle simple pagination patterns (offset, cursor)

### Development Approach
- Start with mock Fivetran responses for faster development
- Create a simple wrapper around Fivetran SDK
- Store connector configurations as JSON files
- Log all operations to console for debugging

## dbt Model Generation

### Simple Model Structure
- Generate basic staging models from source tables
- Create simple aggregation models for common metrics
- Use standard SQL without complex Jinja templating initially
- Focus on readability over optimization

### File Generation
- Generate one staging model per source table
- Create a single mart model with key business metrics
- Include basic schema.yml with table descriptions
- Store generated models in dbt_project folder

## BigQuery Schema Design

### Development Setup
- Use a single development dataset for all tables
- Create tables with AUTO schema detection initially
- Add proper schemas once the pipeline works
- Use simple column names without complex nesting

### Table Organization
- Raw tables: `raw_{source}_{table}`
- Staging tables: `stg_{source}_{table}`
- Mart tables: `mart_{business_area}`
- Keep it flat and simple for the prototype

## Gradio UI Development

### Interface Components
- **Tab 1 - Pipeline Creator**:
  - Text area for requirement description
  - File upload or text input for OpenAPI spec
  - Button to create pipeline
  - Output area showing created components

- **Tab 2 - SQL Chat**:
  - Text input for natural language queries
  - Button to generate and execute SQL
  - DataFrame display for results
  - SQL preview area

- **Tab 3 - Pipeline Status**:
  - Simple status display of created pipelines
  - List of tables and models created
  - Basic sync status (mocked for dev)

### Gradio Best Practices
- Use gr.Blocks() for complex layouts
- Implement proper loading states with gr.Button(loading=True)
- Use gr.State() for maintaining session data
- Display progress with gr.Progress()
- Show clear success/error messages

### UI Flow
- Keep the interface simple and linear
- Guide users through the pipeline creation process
- Provide immediate feedback on actions
- Display generated artifacts (SQL, configs) for transparency

## Development Workflow

### Quick Start Focus
- Get a basic end-to-end flow working first
- Use hardcoded examples to test components
- Iterate quickly without over-engineering
- Focus on the happy path initially

### Code Style (Simplified)
- Write clear, readable code over clever solutions
- Use descriptive variable names
- Add inline comments for complex logic
- Don't worry about perfect abstraction initially
- Refactor once the prototype works

### Testing Approach
- Manual testing through Gradio interface
- Use print statements for debugging
- Create a few example OpenAPI specs for testing
- Write simple integration tests for critical paths
- Don't aim for high coverage in the prototype

## Error Handling (Basic)
- Use try-except blocks for external API calls
- Display user-friendly error messages in Gradio
- Log errors to console for debugging
- Don't implement complex retry logic initially
- Focus on informative error messages

## Configuration Management

### Simple Config Setup
- Use a single config.py file with constants
- Store API keys in a .env file
- Keep configuration minimal and flat
- Use sensible defaults for everything

### Environment Variables
```
GEMINI_API_KEY=your_key_here
FIVETRAN_API_KEY=your_key_here
FIVETRAN_API_SECRET=your_secret_here
GCP_PROJECT_ID=your_project_id
BIGQUERY_DATASET=dev_pipeline_test
```

## MVP Implementation Strategy

### Phase 1: Core Pipeline (Week 1)
- Set up Gemini API connection
- Parse a sample OpenAPI spec
- Generate basic Fivetran config (mocked)
- Create simple BigQuery schemas

### Phase 2: Transformations (Week 2)
- Generate basic staging dbt models
- Create simple aggregation models
- Set up dbt project structure
- Test model compilation

### Phase 3: UI Integration (Week 3)
- Build Gradio interface
- Connect all components
- Implement chat-to-SQL feature
- Add basic error handling

### Phase 4: Testing & Refinement (Week 4)
- Test with multiple OpenAPI specs
- Fix critical bugs
- Improve error messages
- Document the setup process

## Example Use Cases to Support

### E-commerce API
- Orders endpoint with customer and product data
- Generate staging models for each entity
- Create customer lifetime value mart
- Enable "top customers" type queries

### SaaS Metrics API
- Users, subscriptions, and usage endpoints
- Generate MRR and churn calculations
- Create executive dashboard mart
- Support cohort analysis queries

### Event Tracking API
- Events with properties and user data
- Generate event aggregation models
- Create user journey analysis
- Support funnel queries

## Common Development Patterns

### Requirement Analysis Pattern
- Extract source type and endpoints from user description
- Identify key entities and relationships
- Determine necessary transformations
- Infer business metrics needed

### Schema Inference Pattern
- Parse OpenAPI response schemas
- Map JSON types to BigQuery types
- Handle nested objects with STRUCT types
- Add metadata columns (_loaded_at, _source)

### Model Generation Pattern
- One staging model per source entity
- Join related entities in intermediate models
- Aggregate in mart models
- Keep transformations simple and readable

## Debugging Tips
- Print Gemini prompts and responses for debugging
- Log generated SQL and configurations
- Use Gradio's debug=True mode
- Check BigQuery query history for executed SQL
- Validate generated dbt models with dbt compile

## Limitations to Accept (For Now)
- Single user/session at a time
- No authentication or access control
- Basic error handling only
- No cost optimization
- No performance tuning
- Limited to OpenAPI sources
- Simple transformations only
- No incremental loading
- No data quality checks
- No automated testing

## Success Criteria for Dev Prototype
- Can parse an OpenAPI spec and create a pipeline configuration
- Generates valid dbt models that compile successfully
- Creates appropriate BigQuery tables
- Converts natural language to working SQL queries
- Provides a usable Gradio interface
- Works end-to-end for at least one use case
- Completes pipeline creation in reasonable time (<2 minutes)
- Generates documentation of what was created

## What NOT to Focus On
- Performance optimization
- Comprehensive error handling
- Security and authentication
- Multi-user support
- Production deployment
- Monitoring and logging
- Cost management
- Data governance
- Complex transformations
- Edge cases and error scenarios

## Quick Commands for Development
```bash
# Install dependencies
uv add google-generativeai gradio fivetran dbt-core google-cloud-bigquery python-dotenv

# Run Gradio app
python src/ui/app.py

# Test dbt models
cd dbt_project && dbt compile

# Quick BigQuery test
python -c "from google.cloud import bigquery; client = bigquery.Client(); print('Connected!')"

# Generate example pipeline
python scripts/generate_example.py
```

## Resources and Documentation
- Google ADK Documentation: https://google.github.io/adk-docs/
- Gemini API: https://ai.google.dev/
- Gradio Docs: https://gradio.app/docs/
- Fivetran API: https://fivetran.com/docs/rest-api
- dbt Docs: https://docs.getdbt.com/
- BigQuery: https://cloud.google.com/bigquery/docs

## Final Notes
This is a development prototype - the goal is to prove the concept works. Don't get caught up in perfection. Build something that demonstrates the value of AI-automated pipeline creation. Once the prototype works, you can iterate on improvements and production-readiness.